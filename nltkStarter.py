#!/usr/local/bin/python3

import os, sys
#export PATH="/usr/local/opt/python/libexec/bin:$PATH


# Starting NLTK
import nltk
from nltk.book import *

# import stanfordnlp
# nlp = stanfordnlp.Pipeline() # This sets up a default neural pipeline in English
# doc = nlp("Barack Obama was born in Hawaii.  He was elected president in 2008.")
# doc.sentences[0].print_dependencies()


# text1.concordance("find")
# text2.similar("old")
# text3.common_contexts(["sin"])
# text4.dispersion_plot(["citizens", "democracy", "freedom", "duties", "America"])
# text4.generate()

#sorted(set(text3))
#nltk.chat.chatbots(


# NLTK: Bird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python. O’Reilly Media Inc.
''' STANFORD NLP: Peng Qi, Timothy Dozat, Yuhao Zhang and Christopher D. Manning. 2018. 
Universal Dependency Parsing from Scratch In Proceedings of the CoNLL 2018 Shared Task: 
Multilingual Parsing from Raw Text to Universal Dependencies, pp. 160-170. [pdf] [bib] '''

#To activate the StanfordNLP library, switch to Python 3 using: export PATH="/usr/local/opt/python/libexec/bin:$PATH"
 

